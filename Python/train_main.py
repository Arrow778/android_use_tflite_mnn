import os
import tensorflow as tf
from tensorflow.keras import layers, models, applications, regularizers
import matplotlib.pyplot as plt
import os.path as path
from datetime import datetime


# ======================
# é…ç½®å¸¸é‡ï¼ˆå»ºè®®é›†ä¸­ç®¡ç†ï¼‰
# ======================
CONFIG = {
    "IMG_SIZE": (224, 224),          # è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆå®½, é«˜ï¼‰ï¼ŒMobileNetV2 é»˜è®¤ä½¿ç”¨ 224x224
    "BATCH_SIZE": 16,                # æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡åŒ…å«çš„æ ·æœ¬æ•°é‡ï¼›è‹¥ GPU æ˜¾å­˜å……è¶³ï¼ˆ>4GBï¼‰ï¼Œå¯é€‚å½“å¢å¤§ï¼ˆå¦‚ 32ï¼‰
    "EPOCHS": 30,                    # è®­ç»ƒæ€»è½®æ•°ï¼ˆéå†æ•´ä¸ªè®­ç»ƒé›†çš„æ¬¡æ•°ï¼‰
    "LEARNING_RATE": 0.00011888,     # Adam ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡ï¼›å€¼å°äº 0.001ï¼Œé€‚åˆå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹
    "SEED": 123,                     # éšæœºç§å­ï¼Œç”¨äºç¡®ä¿æ•°æ®åˆ’åˆ†å’Œæ•°æ®å¢å¼ºçš„å¯å¤ç°æ€§
    "VAL_RATE": 0.28,                # éªŒè¯é›†å æ€»è®­ç»ƒæ•°æ®çš„æ¯”ä¾‹ï¼ˆæ­¤å¤„ä¸º 28%ï¼‰
    "MODEL_DIR_ROOT": "models",      # ä¿å­˜è®­ç»ƒå TFLite æ¨¡å‹çš„æ ¹ç›®å½•
    "LABEL_DIR_ROOT": "labels",      # ä¿å­˜ç±»åˆ«æ ‡ç­¾æ–‡ä»¶ï¼ˆå¦‚ label-mutil.txtï¼‰çš„æ ¹ç›®å½•
    "DATASET_PATH": "datasets/train_1"  # è®­ç»ƒæ•°æ®é›†çš„æ ¹è·¯å¾„ï¼Œåº”åŒ…å«ä»¥ç±»åˆ«å‘½åçš„å­æ–‡ä»¶å¤¹ï¼ˆæ¯ä¸ªå­æ–‡ä»¶å¤¹å­˜æ”¾å¯¹åº”ç±»åˆ«çš„å›¾ç‰‡ï¼‰
}


def ensure_dirs_exist(model_dir_root: str, label_dir_root: str):
    """ç¡®ä¿æ¨¡å‹å’Œæ ‡ç­¾ç›®å½•å­˜åœ¨"""
    for d in [model_dir_root, label_dir_root]:
        if not path.exists(d):
            print(f"{d} æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            os.makedirs(d)


def calculate_class_weight(source_path: str) -> dict:
    """è®¡ç®—ç±»åˆ«æƒé‡ã€æ€»æ ·æœ¬æ•°å’Œç±»åˆ«æ•°"""
    class_count = {}
    total_count = 0
    class_index = 0

    for class_dir in sorted(os.listdir(source_path)):
        class_path = path.join(source_path, class_dir)
        if not path.isdir(class_path):
            continue
        count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        class_count[class_index] = count
        total_count += count
        class_index += 1

    num_classes = len(class_count)
    class_weights = {}
    if num_classes > 0:
        for idx, count in class_count.items():
            class_weights[idx] = (1.0 / count) * (total_count / num_classes)

    return {
        "class_weights": class_weights,
        "total_count": total_count,
        "num_classes": num_classes
    }


def setup_gpu():
    """é…ç½® GPU å†…å­˜å¢é•¿"""
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            print("GPU è®¾ç½®é”™è¯¯:", e)
    print(f"âœ… TF ç‰ˆæœ¬: {tf.__version__}, GPU å¯ç”¨: {len(gpus) > 0}")


def load_datasets(data_path: str, img_size, batch_size, seed, val_rate):
    """åŠ è½½è®­ç»ƒä¸éªŒè¯æ•°æ®é›†ï¼Œå¹¶åº”ç”¨ cache + prefetch"""
    print("ğŸ” æ­£åœ¨åŠ è½½æ•°æ®é›†ï¼ˆå¯ç”¨ shuffle=Trueï¼‰...")
    train_ds_raw = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=val_rate,
        subset="training",
        seed=seed,
        image_size=img_size,
        batch_size=batch_size,
        label_mode="categorical",
        shuffle=True
    )
    val_ds_raw = tf.keras.utils.image_dataset_from_directory(
        data_path,
        validation_split=val_rate,
        subset="validation",
        seed=seed,
        image_size=img_size,
        batch_size=batch_size,
        label_mode="categorical",
        shuffle=True
    )

    # âœ… å…³é”®ï¼šåœ¨ .cache() ä¹‹å‰ä¿å­˜ class_namesï¼
    class_names = train_ds_raw.class_names

    # ç¼“å­˜ä¸é¢„å–ä¼˜åŒ–
    AUTOTUNE = tf.data.AUTOTUNE
    train_ds = train_ds_raw.cache().prefetch(buffer_size=AUTOTUNE)
    val_ds = val_ds_raw.cache().prefetch(buffer_size=AUTOTUNE)

    return train_ds, val_ds, class_names
def build_training_model(num_classes, img_size):
    """æ„å»ºå¸¦æ•°æ®å¢å¼ºçš„è®­ç»ƒæ¨¡å‹"""
    preprocess_input = applications.mobilenet_v2.preprocess_input

    data_augmentation = tf.keras.Sequential([
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.15),
        layers.RandomZoom(0.2),
        layers.RandomBrightness(0.15),
    ], name="data_augmentation")

    base_model = applications.MobileNetV2(
        input_shape=(*img_size, 3),
        include_top=False,
        weights="imagenet"
    )

    base_model.trainable = True # å¼€å¯å…¨å¾®è°ƒ

    model = models.Sequential([
        layers.Lambda(preprocess_input, input_shape=(*img_size, 3)),
        data_augmentation,
        base_model,
        layers.BatchNormalization(),
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.5),
        layers.Dense(
            num_classes,
            activation="softmax",
            kernel_regularizer=regularizers.l2(1e-2)
        )
    ])
    return model


def build_inference_model(num_classes, img_size):
    """æ„å»ºç”¨äº TFLite å¯¼å‡ºçš„æ¨ç†æ¨¡å‹ï¼ˆæ— æ•°æ®å¢å¼ºï¼‰"""
    preprocess_input = applications.mobilenet_v2.preprocess_input

    base_model = applications.MobileNetV2(
        input_shape=(*img_size, 3),
        include_top=False,
        weights="imagenet"
    )
    base_model.trainable = True

    model = models.Sequential([
        layers.Lambda(preprocess_input, input_shape=(*img_size, 3)),
        base_model,
        layers.BatchNormalization(),
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.0),
        layers.Dense(num_classes, activation="softmax")
    ])
    return model


def plot_training_history(history, save_path="training_curves.png"):
    """ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒæ›²çº¿"""
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='train_accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.title('Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='train_loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.title('Loss')
    plt.legend()
    plt.savefig(save_path)
    print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜ä¸º {save_path}")


def save_labels(class_names, label_dir):
    """ä¿å­˜æ ‡ç­¾æ–‡ä»¶"""
    with open(label_dir, 'w', encoding='utf-8') as f:
        for name in class_names:
            f.write(name + '\n')
    print(f"âœ… æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜: {label_dir}")


def visualize_validation_samples(val_dataset, class_names, save_path="validation_samples.png"):
    """å¯è§†åŒ–éªŒè¯é›†æ ·æœ¬"""
    for images, labels in val_dataset.take(1):
        plt.figure(figsize=(12, 8))
        for i in range(min(9, len(images))):
            plt.subplot(3, 3, i + 1)
            plt.imshow(images[i].numpy().astype("uint8"))
            true_label = int(tf.argmax(labels[i]))
            plt.title(f"Label: {class_names[true_label]}")
            plt.axis('off')
        plt.suptitle("éªŒè¯é›†éšæœºæ ·æœ¬ (9å¼ )", fontsize=16)
        plt.tight_layout()
        plt.savefig(save_path)
        print(f"âœ… éªŒè¯é›†æ ·æœ¬å›¾å·²ä¿å­˜ä¸º {save_path}")
        break


def export_tflite_model(keras_model, model_save_path):
    """å¯¼å‡º TFLite æ¨¡å‹ï¼ˆfloat16 é‡åŒ–ï¼‰"""
    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]
    tflite_model = converter.convert()
    with open(model_save_path, 'wb') as f:
        f.write(tflite_model)
    print(f"âœ… TFLite æ¨¡å‹å·²ä¿å­˜: {model_save_path}")


def main():
    # === åˆå§‹åŒ– ===
    now_str = datetime.now().strftime('%m-%d-%H-%M-%S')
    MODEL_NAME = f"model-mutil-{now_str}.tflite"
    MODEL_DIR = path.join(CONFIG["MODEL_DIR_ROOT"], MODEL_NAME)
    LABEL_DIR = path.join(CONFIG["LABEL_DIR_ROOT"], "label-mutil.txt")

    ensure_dirs_exist(CONFIG["MODEL_DIR_ROOT"], CONFIG["LABEL_DIR_ROOT"])
    setup_gpu()

    # === æ•°æ®å‡†å¤‡ ===
    weight_info = calculate_class_weight(CONFIG["DATASET_PATH"])
    class_weights = weight_info["class_weights"]
    num_classes = weight_info["num_classes"]
    total_count = weight_info["total_count"]

    print(f"num_classes: {num_classes}, total_count: {total_count}")
    for k, v in class_weights.items():
        print(f'class_index: {k}, weight: {v}')

    train_ds, val_ds, class_names = load_datasets(
        data_path=CONFIG["DATASET_PATH"],
        img_size=CONFIG["IMG_SIZE"],
        batch_size=CONFIG["BATCH_SIZE"],
        seed=CONFIG["SEED"],
        val_rate=CONFIG["VAL_RATE"]
    )

    # === æ¨¡å‹æ„å»ºä¸è®­ç»ƒ ===
    train_model = build_training_model(num_classes, CONFIG["IMG_SIZE"])
    train_model.compile(
        optimizer=tf.keras.optimizers.Adam(CONFIG["LEARNING_RATE"]),
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )

    callbacks = [
        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7),
        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, mode='max')
    ]

    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    history = train_model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=CONFIG["EPOCHS"],
        callbacks=callbacks,
        class_weight=class_weights,
        verbose=1
    )

    # === å¯è§†åŒ–ä¸ä¿å­˜ ===
    plot_training_history(history)
    visualize_validation_samples(val_ds, class_names)

    # æ„å»ºæ¨ç†æ¨¡å‹å¹¶å¤åˆ¶æƒé‡
    inference_model = build_inference_model(num_classes, CONFIG["IMG_SIZE"])
    inference_model.set_weights(train_model.get_weights())

    export_tflite_model(inference_model, MODEL_DIR)
    save_labels(class_names, LABEL_DIR)


if __name__ == "__main__":
    main()